from astrbot.api.event import filter, AstrMessageEvent, MessageEventResult
from astrbot.api.star import Context, Star, register
from astrbot.api import logger, AstrBotConfig
from astrbot.core.star.filter.event_message_type import EventMessageType
import json
import re
import requests
from typing import List, Dict, Optional, Tuple
from datetime import datetime, timedelta
import os
from pathlib import Path

# é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆä¿ç•™ç”¨äºå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
CONFIG_FILE = Path(__file__).parent / "config.json"

@register("helloworld", "YourName", "ä¸€ä¸ªé›†æˆäº†ç½‘ç›˜æœç´¢è½¬å­˜åŠŸèƒ½çš„æ’ä»¶", "2.0.0")
class MyPlugin(Star):
    def __init__(self, context: Context, config: AstrBotConfig):
        super().__init__(context)
        self.config = config
        
        # åˆå§‹åŒ–ç½‘ç›˜æœç´¢è½¬å­˜åŠŸèƒ½
        self.pansou_api_url = self.config.get("pansou_api_url", "http://154.12.83.97:8085")
        self.ziliao_api_url = self.config.get("ziliao_api_url", "https://www.ziliao.xyz")
        self.ziliao_api_key = self.config.get("ziliao_api_key", "")
        self.ziliao_api_path = self.config.get("ziliao_api_path", "/api/open/transfer")
        self.max_results = self.config.get("max_results", 50)
        self.timeout = self.config.get("timeout", 30)
        self.group_owner_id = self.config.get("group_owner_id", "")
        self.page_size = self.config.get("page_size", 6)  # æ¯é¡µæ˜¾ç¤º6ä¸ªç»“æœ
        self.links_per_type = self.config.get("links_per_type", 3)  # æ¯ç§ç½‘ç›˜æ¯è½®æ˜¾ç¤º2æ¡
        
        # ç¡®ä¿ API URL ä¸ä»¥ / ç»“å°¾
        self.pansou_api_url = self.pansou_api_url.rstrip('/')
        self.ziliao_api_url = self.ziliao_api_url.rstrip('/')
        
        # ä¼šè¯çŠ¶æ€ç®¡ç†ï¼ˆå­˜å‚¨ç”¨æˆ·çš„æœç´¢ç»“æœå’Œåˆ†é¡µçŠ¶æ€ï¼‰
        self.user_sessions = {}  # {user_id: {'keyword': str, 'results': list, 'timestamp': datetime, 'current_page': int}}
        self.session_timeout = timedelta(minutes=5)  # ä¼šè¯5åˆ†é’Ÿè¿‡æœŸ
        
        # ç½‘ç›˜ç±»å‹ä¸­æ–‡åç§°æ˜ å°„
        self.cloud_type_names = {
            "baidu": "ç™¾åº¦ç½‘ç›˜",
            "aliyun": "é˜¿é‡Œäº‘ç›˜",
            "quark": "å¤¸å…‹ç½‘ç›˜",
            "tianyi": "å¤©ç¿¼äº‘ç›˜",
            "uc": "UCç½‘ç›˜",
            "mobile": "ç§»åŠ¨äº‘ç›˜",
            "115": "115ç½‘ç›˜",
            "pikpak": "PikPak",
            "xunlei": "è¿…é›·ç½‘ç›˜",
            "123": "123ç½‘ç›˜",
            "magnet": "ç£åŠ›é“¾æ¥",
            "ed2k": "ç”µé©´é“¾æ¥",
            "others": "å…¶ä»–"
        }
        
        logger.info(f"[PanSearch] å¢å¼ºç‰ˆæ’ä»¶åˆå§‹åŒ–å®Œæˆ")

    async def initialize(self):
        """å¯é€‰æ‹©å®ç°å¼‚æ­¥çš„æ’ä»¶åˆå§‹åŒ–æ–¹æ³•ï¼Œå½“å®ä¾‹åŒ–è¯¥æ’ä»¶ç±»ä¹‹åä¼šè‡ªåŠ¨è°ƒç”¨è¯¥æ–¹æ³•ã€‚"""

    # æ³¨å†ŒæŒ‡ä»¤çš„è£…é¥°å™¨ã€‚æŒ‡ä»¤åä¸º helloworldã€‚æ³¨å†ŒæˆåŠŸåï¼Œå‘é€ `/helloworld` å°±ä¼šè§¦å‘è¿™ä¸ªæŒ‡ä»¤ï¼Œå¹¶å›å¤ `ä½ å¥½, {user_name}!`
    @filter.command("helloworld")
    async def helloworld(self, event: AstrMessageEvent, *args, **kwargs):
        """è¿™æ˜¯ä¸€ä¸ª hello world æŒ‡ä»¤"""
        user_name = event.get_sender_name()
        message_str = event.message_str # ç”¨æˆ·å‘çš„çº¯æ–‡æœ¬æ¶ˆæ¯å­—ç¬¦ä¸²
        message_chain = event.get_messages() # ç”¨æˆ·æ‰€å‘çš„æ¶ˆæ¯çš„æ¶ˆæ¯é“¾
        logger.info(message_chain)
        yield event.plain_result(f"Hello, {user_name}, ä½ å‘äº† {message_str}!") # å‘é€ä¸€æ¡çº¯æ–‡æœ¬æ¶ˆæ¯
    
    # æ³¨å†ŒæŒ‡ä»¤ï¼šæœç´¢
    @filter.command("search")
    async def search(self, event: AstrMessageEvent, *args, **kwargs):
        """æœç´¢ç½‘ç›˜èµ„æºï¼Œæ ¼å¼ï¼š/search å…³é”®è¯"""
        message_str = event.message_str.strip()
        if not message_str:
            yield event.plain_result("âŒ è¯·è¾“å…¥æœç´¢å…³é”®è¯ï¼Œæ ¼å¼ï¼š/search å…³é”®è¯")
            return
            
        user_id = str(event.get_sender_id())
        result = self._handle_search(message_str, user_id)
        yield event.plain_result(result)
    
    # æ³¨å†ŒæŒ‡ä»¤ï¼šè½¬å­˜
    @filter.command("transfer")
    async def transfer(self, event: AstrMessageEvent, *args, **kwargs):
        """è½¬å­˜ç½‘ç›˜èµ„æºï¼Œæ ¼å¼ï¼š/transfer åºå·"""
        message_str = event.message_str.strip()
        if not message_str:
            yield event.plain_result("âŒ è¯·è¾“å…¥åºå·ï¼Œæ ¼å¼ï¼š/transfer åºå·")
            return
            
        user_id = str(event.get_sender_id())
        result = self._handle_transfer(message_str, user_id)
        yield event.plain_result(result)
    
    # æ³¨å†ŒæŒ‡ä»¤ï¼šç¿»é¡µ
    @filter.command("next")
    async def next_page(self, event: AstrMessageEvent, *args, **kwargs):
        """æŸ¥çœ‹ä¸‹ä¸€é¡µæœç´¢ç»“æœ"""
        user_id = str(event.get_sender_id())
        result = self._handle_page_navigation("next", user_id)
        yield event.plain_result(result)
    
    @filter.command("prev")
    async def prev_page(self, event: AstrMessageEvent, *args, **kwargs):
        """æŸ¥çœ‹ä¸Šä¸€é¡µæœç´¢ç»“æœ"""
        user_id = str(event.get_sender_id())
        result = self._handle_page_navigation("prev", user_id)
        yield event.plain_result(result)
    
    # å¤„ç†æ™®é€šæ¶ˆæ¯
    @filter.event_message_type(EventMessageType.ALL)
    async def handle_any_message(self, event: AstrMessageEvent, *args, **kwargs):
        """å¤„ç†æ‰€æœ‰æ¶ˆæ¯ï¼Œæ”¯æŒï¼šæœXXã€æ±‚XXã€æœç´¢XXã€æ‰¾XX"""
        # æ£€æŸ¥æ˜¯å¦ä¸ºç¾¤æˆå‘˜åŠ å…¥äº‹ä»¶
        try:
            # è·å–äº‹ä»¶ç±»å‹
            event_type = None
            if hasattr(event, 'event_type'):
                event_type = event.event_type
            elif hasattr(event, 'message_type'):
                event_type = event.message_type
            
            # æ£€æŸ¥æ¶ˆæ¯å†…å®¹æ˜¯å¦åŒ…å«ç¾¤æˆå‘˜åŠ å…¥çš„ç‰¹å¾
            message_str = event.message_str
            message_chain = event.get_messages()
            
            # å¸¸è§çš„ç¾¤æˆå‘˜åŠ å…¥æ¶ˆæ¯ç‰¹å¾
            join_keywords = ['åŠ å…¥äº†ç¾¤èŠ', 'åŠ å…¥ç¾¤èŠ', 'å·²åŠ å…¥', 'æ–°æˆå‘˜', 'welcome', 'Welcome']
            is_join_event = False
            
            # æ£€æŸ¥æ¶ˆæ¯å­—ç¬¦ä¸²ä¸­æ˜¯å¦åŒ…å«åŠ å…¥å…³é”®è¯
            if any(keyword in message_str for keyword in join_keywords):
                is_join_event = True
            
            # æ£€æŸ¥æ¶ˆæ¯é“¾ä¸­æ˜¯å¦æœ‰ç›¸å…³å…ƒç´ 
            if message_chain and not is_join_event:
                for msg in message_chain:
                    if hasattr(msg, 'type') and msg.type in ['MemberJoin', 'MemberJoinEvent', 'ç¾¤æˆå‘˜åŠ å…¥', 'å…¥ç¾¤']:
                        is_join_event = True
                        break
                    # æ£€æŸ¥æ¶ˆæ¯å†…å®¹
                    if hasattr(msg, 'content') and any(keyword in msg.content for keyword in join_keywords):
                        is_join_event = True
                        break
            
            # å¦‚æœæ˜¯ç¾¤æˆå‘˜åŠ å…¥äº‹ä»¶ï¼Œå‘é€æ¬¢è¿æ¶ˆæ¯
            if is_join_event:
                # è·å–æ–°åŠ å…¥çš„ç”¨æˆ·ä¿¡æ¯
                user_name = event.get_sender_name()
                # å‘é€æ¬¢è¿æ¶ˆæ¯
                welcome_message = f"@{user_name} æ¬¢è¿å°ä¼™ä¼´ï¼Œæƒ³è¦çœ‹å•¥å‰§ï¼Œè¾“å…¥æœ+å‰§åå‘ç¾¤é‡Œå¹¶è¾“å…¥æ•°å­—å³å¯è·å–é“¾æ¥\n\nPS:æœç´¢åŠŸèƒ½æ˜¯æœºå™¨äººå›å¤çš„ï¼Œç¾¤ä¸»æ²¡æ³•å®æ—¶çœ‹ç¾¤ï¼Œæœ‰é—®é¢˜@ç¾¤ä¸»ç­‰å¾…å¤„ç†"
                yield event.plain_result(welcome_message)
                return
        except Exception as e:
            logger.error(f"[PanSearch] å¤„ç†ç¾¤æˆå‘˜åŠ å…¥äº‹ä»¶å¼‚å¸¸: {str(e)}")
        
        message_str = event.message_str.strip()
        user_id = str(event.get_sender_id())
        message_chain = event.get_messages()
        
        # æ£€æŸ¥æ˜¯å¦è¢«@
        is_at_me = False
        try:
            # è·å–æœºå™¨äººè‡ªèº«ä¿¡æ¯
            if hasattr(event, 'bot'):
                bot = event.bot
                bot_id = str(bot.get('user_id', ''))
                bot_name = bot.get('nickname', '')
            else:
                # å¦‚æœæ²¡æœ‰botå±æ€§ï¼Œå°è¯•ä½¿ç”¨å…¶ä»–æ–¹å¼è·å–æœºå™¨äººä¿¡æ¯
                bot_id = ''
                bot_name = ''
            
            # æ£€æŸ¥æ¶ˆæ¯é“¾ä¸­æ˜¯å¦æœ‰@æœºå™¨äººçš„å…ƒç´ 
            if message_chain:
                for msg in message_chain:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯Atç±»å‹çš„æ¶ˆæ¯
                    if hasattr(msg, 'type') and msg.type in ['At', 'at']:
                        # æ£€æŸ¥Atçš„å¯¹è±¡æ˜¯å¦æ˜¯æœºå™¨äºº
                        if hasattr(msg, 'target') and str(msg.target) == bot_id:
                            is_at_me = True
                            break
                        elif hasattr(msg, 'qq') and str(msg.qq) == bot_id:
                            is_at_me = True
                            break
                    # æ£€æŸ¥æ¶ˆæ¯å†…å®¹ä¸­æ˜¯å¦åŒ…å«æœºå™¨äººåç§°
                    if hasattr(msg, 'content') and bot_name in msg.content:
                        is_at_me = True
                        break
        except Exception as e:
            logger.error(f"[PanSearch] æ£€æŸ¥@äº‹ä»¶å¼‚å¸¸: {str(e)}")
        
        # å¦‚æœè¢«@ï¼Œå‘é€ä½¿ç”¨è¯´æ˜
        if is_at_me:
            help_message = "æƒ³è¦çœ‹å•¥å‰§ï¼Œè¾“å…¥æœ+å‰§åå‘ç¾¤é‡Œå¹¶è¾“å…¥æ•°å­—å³å¯è·å–é“¾æ¥\nå¦‚ \"æœä»™é€†\" è·³å‡ºæ¥çš„å¯¹è¯ å¦‚ \"2\"\nPS:æœç´¢åŠŸèƒ½æ˜¯æœºå™¨äººå›å¤çš„ï¼Œç¾¤ä¸»æ²¡æ³•å®æ—¶çœ‹ç¾¤ï¼Œæœ‰é—®é¢˜@ç¾¤ä¸»ç­‰ç¾¤ä¸»æ¥è§£å†³å°±è¡Œ"
            yield event.plain_result(help_message)
            return
        
        # å¤„ç†æœç´¢æŒ‡ä»¤ï¼ˆæ”¯æŒï¼šæœXXã€ç™¾åº¦XXã€å¤¸å…‹XXã€UCXXã€è¿…é›·XXï¼‰
        search_patterns = [
            r'^æœ(.+)$',  # åŸæœ‰çš„æœç´¢æ ¼å¼
            r'^ç™¾åº¦(.+)$',  # ç™¾åº¦ç½‘ç›˜æœç´¢
            r'^å¤¸å…‹(.+)$',  # å¤¸å…‹ç½‘ç›˜æœç´¢
            r'^UC(.+)$',   # UCç½‘ç›˜æœç´¢
            r'^è¿…é›·(.+)$',  # è¿…é›·ç½‘ç›˜æœç´¢
        ]
        
        keyword = None
        cloud_type = "all"  # é»˜è®¤æœç´¢æ‰€æœ‰ç½‘ç›˜
        
        for pattern in search_patterns:
            match = re.match(pattern, message_str)
            if match:
                keyword = match.group(1).strip()
                # æ ¹æ®åŒ¹é…çš„æ¨¡å¼ç¡®å®šç½‘ç›˜ç±»å‹
                if pattern == r'^ç™¾åº¦(.+)$':
                    cloud_type = "baidu"
                elif pattern == r'^å¤¸å…‹(.+)$':
                    cloud_type = "quark"
                elif pattern == r'^UC(.+)$':
                    cloud_type = "uc"
                elif pattern == r'^è¿…é›·(.+)$':
                    cloud_type = "xunlei"
                break
        
        if keyword:
            # å‘é€æœç´¢ä¸­æç¤º
            yield event.plain_result("ğŸ” æœç´¢ä¸­ï¼Œè¯·ç­‰å¾…")
            
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = datetime.now()
            
            result = self._handle_search(keyword, user_id, cloud_type)
            
            # è®¡ç®—è€—æ—¶
            end_time = datetime.now()
            elapsed_time = (end_time - start_time).total_seconds()
            
            # è·å–ç”¨æˆ·åç§°ç”¨äº@
            user_name = event.get_sender_name()
            
            # æ·»åŠ @ç”¨æˆ·ã€æœ‰æ•ˆæœŸå’Œè€—æ—¶ä¿¡æ¯
            session = self.user_sessions.get(user_id, {})
            current_page = session.get('current_page', 1)
            
            # ç»„åˆæœ€ç»ˆç»“æœ
            final_result = f"@{user_name}\n"
            final_result += result
            final_result += f"\nğŸ’¡ åºå·æœ‰æ•ˆæœŸ5åˆ†é’Ÿï¼Œè¿‡æœŸè¯·é‡æ–°æœç´¢\n"
            final_result += f"â±ï¸  æœ¬æ¬¡æ“ä½œè€—æ—¶ï¼š{elapsed_time:.2f}ç§’\n"
            final_result += f"ğŸ“„ å½“å‰é¡µï¼š{current_page}"
            
            yield event.plain_result(final_result)
            return
        
        # å¤„ç†ç¿»é¡µå‘½ä»¤
        if message_str in ["ä¸‹ä¸€é¡µ", "ä¸‹ä¸€é ", "next", "ä¸‹é¡µ", "ä¸‹é "]:
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = datetime.now()
            
            result = self._handle_page_navigation("next", user_id)
            
            # è®¡ç®—è€—æ—¶
            end_time = datetime.now()
            elapsed_time = (end_time - start_time).total_seconds()
            
            # è·å–ç”¨æˆ·åç§°ç”¨äº@
            user_name = event.get_sender_name()
            
            # æ·»åŠ @ç”¨æˆ·ã€æœ‰æ•ˆæœŸå’Œè€—æ—¶ä¿¡æ¯
            session = self.user_sessions.get(user_id, {})
            current_page = session.get('current_page', 1)
            
            # ç»„åˆæœ€ç»ˆç»“æœ
            final_result = f"@{user_name}\n"
            final_result += result
            final_result += f"\nğŸ’¡ åºå·æœ‰æ•ˆæœŸ5åˆ†é’Ÿï¼Œè¿‡æœŸè¯·é‡æ–°æœç´¢\n"
            final_result += f"â±ï¸  æœ¬æ¬¡æ“ä½œè€—æ—¶ï¼š{elapsed_time:.2f}ç§’\n"
            final_result += f"ğŸ“„ å½“å‰é¡µï¼š{current_page}"
            
            yield event.plain_result(final_result)
            return
        
        if message_str in ["ä¸Šä¸€é¡µ", "ä¸Šä¸€é ", "prev", "previous", "ä¸Šé¡µ", "ä¸Šé "]:
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = datetime.now()
            
            result = self._handle_page_navigation("prev", user_id)
            
            # è®¡ç®—è€—æ—¶
            end_time = datetime.now()
            elapsed_time = (end_time - start_time).total_seconds()
            
            # è·å–ç”¨æˆ·åç§°ç”¨äº@
            user_name = event.get_sender_name()
            
            # æ·»åŠ @ç”¨æˆ·ã€æœ‰æ•ˆæœŸå’Œè€—æ—¶ä¿¡æ¯
            session = self.user_sessions.get(user_id, {})
            current_page = session.get('current_page', 1)
            
            # ç»„åˆæœ€ç»ˆç»“æœ
            final_result = f"@{user_name}\n"
            final_result += result
            final_result += f"\nğŸ’¡ åºå·æœ‰æ•ˆæœŸ5åˆ†é’Ÿï¼Œè¿‡æœŸè¯·é‡æ–°æœç´¢\n"
            final_result += f"â±ï¸  æœ¬æ¬¡æ“ä½œè€—æ—¶ï¼š{elapsed_time:.2f}ç§’\n"
            final_result += f"ğŸ“„ å½“å‰é¡µï¼š{current_page}"
            
            yield event.plain_result(final_result)
            return
        
        # å¤„ç†é€‰æ‹©å‘½ä»¤ï¼ˆæ”¯æŒï¼šç¬¬Xä¸ªã€Xã€é€‰æ‹©Xï¼‰
        # åªæœ‰åœ¨ç”¨æˆ·æœç´¢ä¹‹åæ‰ä¼šå¤„ç†é€‰æ‹©å‘½ä»¤
        if user_id in self.user_sessions:
            select_patterns = [
                r'^ç¬¬(\d+)ä¸ª$',
                r'^ç¬¬(\d+)å€‹$',
                r'^(\d+)$',
                r'^é€‰æ‹©(\d+)$',
                r'^é¸æ“‡(\d+)$',
                r'^è½¬å­˜(\d+)$',
            ]
            
            selected_index = None
            for pattern in select_patterns:
                match = re.match(pattern, message_str)
                if match:
                    selected_index = int(match.group(1))
                    break
            
            if selected_index is not None:
                # è®°å½•å¼€å§‹æ—¶é—´
                start_time = datetime.now()
                
                result = self._handle_select(selected_index, user_id)
                
                # è®¡ç®—è€—æ—¶
                end_time = datetime.now()
                elapsed_time = (end_time - start_time).total_seconds()
                
                # æ·»åŠ è€—æ—¶ä¿¡æ¯
                result += f"\nâ±ï¸  æœ¬æ¬¡æ“ä½œè€—æ—¶ï¼š{elapsed_time:.2f}ç§’"
                
                yield event.plain_result(result)
                return

    async def terminate(self):
        """å¯é€‰æ‹©å®ç°å¼‚æ­¥çš„æ’ä»¶é”€æ¯æ–¹æ³•ï¼Œå½“æ’ä»¶è¢«å¸è½½/åœç”¨æ—¶ä¼šè°ƒç”¨ã€‚"""
        logger.info(f"[PanSearch] æ’ä»¶å·²å¸è½½")
    
    # å†…éƒ¨æ–¹æ³•ï¼šæ¸…ç†è¿‡æœŸä¼šè¯
    def _cleanup_expired_sessions(self):
        now = datetime.now()
        expired_users = []
        for user_id, session in self.user_sessions.items():
            if now - session['timestamp'] > self.session_timeout:
                expired_users.append(user_id)
        for user_id in expired_users:
            del self.user_sessions[user_id]
    
    # å†…éƒ¨æ–¹æ³•ï¼šæœç´¢èµ„æº
    def _search_resources(self, keyword: str, src: str = "all") -> Dict:
        try:
            url = f"{self.pansou_api_url}/api/search"
            payload = {
                "kw": keyword,
                "res": "merge",
                "src": src
            }
            
            logger.info(f"[PanSearch] æœç´¢å…³é”®è¯: {keyword}, ç½‘ç›˜ç±»å‹: {src}")
            logger.info(f"[PanSearch] APIè¯·æ±‚URL: {url}")
            logger.info(f"[PanSearch] APIè¯·æ±‚å‚æ•°: {json.dumps(payload)}")
            
            response = requests.post(
                url,
                json=payload,
                timeout=self.timeout
            )
            response.raise_for_status()
            
            result = response.json()
            logger.info(f"[PanSearch] APIå“åº”: {json.dumps(result)}")
            logger.info(f"[PanSearch] APIå“åº”ç±»å‹: {type(result)}")
            logger.info(f"[PanSearch] APIå“åº”åŒ…å«çš„é”®: {list(result.keys())}")
            
            if result.get("code") == 0:
                logger.info(f"[PanSearch] APIè¿”å›æˆåŠŸçŠ¶æ€ç ")
                
                # æ£€æŸ¥å„ç§å¯èƒ½çš„æ•°æ®ç»“æ„
                if result.get("data"):
                    data = result.get("data", {})
                    logger.info(f"[PanSearch] ä»dataå­—æ®µè·å–æœç´¢ç»“æœ")
                    logger.info(f"[PanSearch] dataå­—æ®µç±»å‹: {type(data)}")
                    logger.info(f"[PanSearch] dataåŒ…å«çš„é”®: {list(data.keys())}")
                    
                    # æ£€æŸ¥dataå­—æ®µæ˜¯å¦åŒ…å«æœ‰æ•ˆæ•°æ®
                    if isinstance(data, dict) and (data.get('total', 0) > 0 or data.get('links', []) or data.get('merged_by_type', {})):
                        logger.info(f"[PanSearch] æœç´¢æˆåŠŸï¼Œæ‰¾åˆ° {data.get('total', 0)} æ¡ç»“æœ")
                        return data
                    elif isinstance(data, list):
                        logger.info(f"[PanSearch] dataå­—æ®µæ˜¯åˆ—è¡¨ï¼Œé•¿åº¦: {len(data)}")
                        # å¦‚æœdataæ˜¯åˆ—è¡¨ï¼Œå¯èƒ½ç›´æ¥åŒ…å«ç»“æœ
                        return {"total": len(data), "links": data}
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å¯èƒ½çš„æ•°æ®ç»“æ„
                elif "links" in result:
                    logger.info(f"[PanSearch] ç›´æ¥ä»APIå“åº”è·å–linkså­—æ®µ")
                    links = result.get("links", [])
                    return {"total": len(links), "links": links}
                
                elif "merged_by_type" in result:
                    logger.info(f"[PanSearch] ç›´æ¥ä»APIå“åº”è·å–merged_by_typeå­—æ®µ")
                    merged_by_type = result.get("merged_by_type", {})
                    # è®¡ç®—æ€»ç»“æœæ•°
                    total = sum(len(links) for links in merged_by_type.values())
                    return {"total": total, "merged_by_type": merged_by_type}
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é¢„æœŸçš„æ•°æ®ç»“æ„ï¼Œä½†è¿”å›ç æ˜¯0
                logger.warning(f"[PanSearch] APIè¿”å›æˆåŠŸï¼Œä½†æ•°æ®ç»“æ„ä¸ç¬¦åˆé¢„æœŸ: {json.dumps(result)}")
                return result
            else:
                logger.error(f"[PanSearch] æœç´¢å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                # å³ä½¿è¿”å›ç ä¸æ˜¯0ï¼Œä¹Ÿå°è¯•è¿”å›å¯èƒ½çš„æ•°æ®
                if result.get("data"):
                    logger.info(f"[PanSearch] APIè¿”å›é”™è¯¯ç ï¼Œä½†åŒ…å«dataå­—æ®µ")
                    return result.get("data", {})
                return {}
                
        except requests.exceptions.RequestException as e:
            logger.error(f"[PanSearch] æœç´¢è¯·æ±‚å¼‚å¸¸: {str(e)}")
            return {}
        except Exception as e:
            logger.error(f"[PanSearch] æœç´¢å¤„ç†å¼‚å¸¸: {str(e)}")
            logger.exception("[PanSearch] æœç´¢å¼‚å¸¸è¯¦ç»†ä¿¡æ¯")
            return {}
    
    # å†…éƒ¨æ–¹æ³•ï¼šæå–é“¾æ¥
    def _extract_all_links(self, search_result: Dict) -> List[Dict]:
        logger.info(f"[PanSearch] æå–é“¾æ¥å¼€å§‹ï¼Œæœç´¢ç»“æœç±»å‹: {type(search_result)}, å†…å®¹: {json.dumps(search_result)}")
        logger.info(f"[PanSearch] æœç´¢ç»“æœåŒ…å«çš„é”®: {list(search_result.keys())}")
        merged_by_type = search_result.get("merged_by_type", {})
        
        # åªæ”¯æŒè¿™4ç§ç½‘ç›˜ç±»å‹ï¼ŒæŒ‰é¡ºåºï¼šå¤¸å…‹ã€ç™¾åº¦ã€UCã€è¿…é›·
        cloud_types = ["quark", "baidu", "uc", "xunlei"]
        
        # æŒ‰ç±»å‹æ”¶é›†é“¾æ¥
        max_links_per_type = 100
        all_links_by_type = {}
        
        # æ£€æŸ¥æ˜¯å¦æœ‰merged_by_typeå­—æ®µï¼ˆå…¨ç±»å‹æœç´¢æ—¶è¿”å›ï¼‰
        if merged_by_type:
            logger.info(f"[PanSearch] æ‰¾åˆ°merged_by_typeå­—æ®µï¼Œç±»å‹: {type(merged_by_type)}, å†…å®¹: {json.dumps(merged_by_type)}")
            logger.info(f"[PanSearch] merged_by_typeåŒ…å«çš„é”®: {list(merged_by_type.keys())}")
            for cloud_type in cloud_types:
                if cloud_type in merged_by_type:
                    logger.info(f"[PanSearch] æ‰¾åˆ°{cloud_type}ç±»å‹çš„é“¾æ¥ï¼Œæ•°é‡: {len(merged_by_type[cloud_type])}")
                    type_links = []
                    for link in merged_by_type[cloud_type][:max_links_per_type]:
                        logger.info(f"[PanSearch] å¤„ç†é“¾æ¥: {link}")
                        type_links.append({
                            "url": link.get("url", ""),
                            "password": link.get("password", ""),
                            "note": link.get("note", ""),
                            "type": cloud_type,
                            "source": link.get("source", "")
                        })
                    if type_links:
                        all_links_by_type[cloud_type] = type_links
                        logger.info(f"[PanSearch] æå–åˆ°{cloud_type}ç±»å‹çš„{len(type_links)}ä¸ªé“¾æ¥")
        else:
            logger.info(f"[PanSearch] æ²¡æœ‰æ‰¾åˆ°merged_by_typeå­—æ®µï¼Œå°è¯•å…¶ä»–æ•°æ®ç»“æ„")
            # æ²¡æœ‰merged_by_typeå­—æ®µï¼Œå¯èƒ½æ˜¯ç‰¹å®šç½‘ç›˜ç±»å‹æœç´¢
            # å°è¯•ä»ç›´æ¥ç»“æœä¸­æå–é“¾æ¥
            links = search_result.get("links", [])
            logger.info(f"[PanSearch] ç›´æ¥linkså­—æ®µæ•°é‡: {len(links)}")
            if links:
                logger.info(f"[PanSearch] æ‰¾åˆ°ç›´æ¥linkså­—æ®µ: {len(links)}ä¸ªé“¾æ¥")
                logger.info(f"[PanSearch] ç¬¬ä¸€ä¸ªé“¾æ¥å†…å®¹: {links[0] if links else 'æ— '}")
                # ç¡®å®šå½“å‰æœç´¢çš„ç½‘ç›˜ç±»å‹
                current_src = search_result.get("src", "")
                logger.info(f"[PanSearch] å½“å‰æœç´¢çš„ç½‘ç›˜ç±»å‹: {current_src}")
                if current_src in cloud_types:
                    # åˆ›å»ºè¯¥ç±»å‹çš„é“¾æ¥åˆ—è¡¨
                    type_links = []
                    for link in links[:max_links_per_type]:
                        type_links.append({
                            "url": link.get("url", ""),
                            "password": link.get("password", ""),
                            "note": link.get("note", ""),
                            "type": current_src,
                            "source": link.get("source", "")
                        })
                    if type_links:
                        all_links_by_type[current_src] = type_links
                        logger.info(f"[PanSearch] æå–åˆ°{current_src}ç±»å‹çš„{len(type_links)}ä¸ªé“¾æ¥")
            else:
                logger.info(f"[PanSearch] æ²¡æœ‰æ‰¾åˆ°ç›´æ¥linkså­—æ®µï¼Œå°è¯•æŒ‰ç½‘ç›˜ç±»å‹æŸ¥æ‰¾")
                # å°è¯•å¦ä¸€ç§å¯èƒ½çš„æ•°æ®ç»“æ„
                for cloud_type in cloud_types:
                    if cloud_type in search_result:
                        logger.info(f"[PanSearch] æ‰¾åˆ°{cloud_type}å­—æ®µï¼Œå†…å®¹: {search_result[cloud_type]}")
                        type_links = []
                        for link in search_result[cloud_type][:max_links_per_type]:
                            type_links.append({
                                "url": link.get("url", ""),
                                "password": link.get("password", ""),
                                "note": link.get("note", ""),
                                "type": cloud_type,
                                "source": link.get("source", "")
                            })
                        if type_links:
                            all_links_by_type[cloud_type] = type_links
                            logger.info(f"[PanSearch] æå–åˆ°{cloud_type}ç±»å‹çš„{len(type_links)}ä¸ªé“¾æ¥")
            
            # å°è¯•ä¸€ç§æ–°çš„å¯èƒ½æ•°æ®ç»“æ„ï¼ˆç‰¹å®šç½‘ç›˜æœç´¢å¯èƒ½è¿”å›çš„ç»“æ„ï¼‰
            if not all_links_by_type and "data" in search_result:
                logger.info(f"[PanSearch] å°è¯•ä»dataå­—æ®µæå–é“¾æ¥")
                data = search_result.get("data", {})
                logger.info(f"[PanSearch] dataå­—æ®µå†…å®¹: {json.dumps(data)}")
                logger.info(f"[PanSearch] dataåŒ…å«çš„é”®: {list(data.keys())}")
                
                # æ£€æŸ¥dataå­—æ®µæ˜¯å¦åŒ…å«links
                data_links = data.get("links", [])
                if data_links:
                    logger.info(f"[PanSearch] ä»dataå­—æ®µæ‰¾åˆ°links: {len(data_links)}ä¸ªé“¾æ¥")
                    current_src = data.get("src", "") or search_result.get("src", "")
                    logger.info(f"[PanSearch] å½“å‰æœç´¢çš„ç½‘ç›˜ç±»å‹: {current_src}")
                    if current_src in cloud_types:
                        type_links = []
                        for link in data_links[:max_links_per_type]:
                            type_links.append({
                                "url": link.get("url", ""),
                                "password": link.get("password", ""),
                                "note": link.get("note", ""),
                                "type": current_src,
                                "source": link.get("source", "")
                            })
                        if type_links:
                            all_links_by_type[current_src] = type_links
                            logger.info(f"[PanSearch] ä»dataå­—æ®µæå–åˆ°{current_src}ç±»å‹çš„{len(type_links)}ä¸ªé“¾æ¥")
            
            # æœ€åå°è¯•ä¸€ç§å¯èƒ½çš„æ•°æ®ç»“æ„
            if not all_links_by_type:
                logger.info(f"[PanSearch] å°è¯•ç›´æ¥ä»æœç´¢ç»“æœæå–æ‰€æœ‰å¯èƒ½çš„é“¾æ¥")
                for key, value in search_result.items():
                    if isinstance(value, list):
                        logger.info(f"[PanSearch] æ£€æŸ¥{key}å­—æ®µï¼Œç±»å‹ä¸ºåˆ—è¡¨ï¼Œé•¿åº¦: {len(value)}")
                        if value and isinstance(value[0], dict):
                            logger.info(f"[PanSearch] {key}å­—æ®µåŒ…å«å­—å…¸åˆ—è¡¨ï¼Œå°è¯•æå–é“¾æ¥")
                            # ç¡®å®šå¯èƒ½çš„ç½‘ç›˜ç±»å‹
                            possible_types = [t for t in cloud_types if t in str(key).lower() or t in str(search_result.get("src", ""))]
                            cloud_type = possible_types[0] if possible_types else "other"
                            
                            type_links = []
                            for link in value[:max_links_per_type]:
                                if "url" in link or "link" in link:
                                    type_links.append({
                                        "url": link.get("url", link.get("link", "")),
                                        "password": link.get("password", link.get("pwd", "")),
                                        "note": link.get("note", link.get("title", "")),
                                        "type": cloud_type,
                                        "source": link.get("source", "")
                                    })
                            if type_links:
                                all_links_by_type[cloud_type] = type_links
                                logger.info(f"[PanSearch] ç›´æ¥æå–åˆ°{cloud_type}ç±»å‹çš„{len(type_links)}ä¸ªé“¾æ¥")
        
        # æŒ‰è½®æ¬¡æ’åˆ—ï¼šæ¯è½®éƒ½æ˜¯ å¤¸å…‹2æ¡ -> ç™¾åº¦2æ¡ -> UC2æ¡ -> è¿…é›·2æ¡
        links = []
        
        # è®¡ç®—æœ€å¤§éœ€è¦å¤šå°‘è½®
        max_links_per_type = max([len(links) for links in all_links_by_type.values()], default=0)
        max_rounds = (max_links_per_type + self.links_per_type - 1) // self.links_per_type
        
        logger.info(f"[PanSearch] æœ€å¤§è½®æ¬¡: {max_rounds}, æ¯è½®é“¾æ¥æ•°: {self.links_per_type}")
        
        for round_num in range(max_rounds):
            for cloud_type in cloud_types:
                if cloud_type in all_links_by_type:
                    type_links = all_links_by_type[cloud_type]
                    start_idx = round_num * self.links_per_type
                    end_idx = start_idx + self.links_per_type
                    round_links = type_links[start_idx:end_idx]
                    if round_links:
                        logger.info(f"[PanSearch] ç¬¬{round_num+1}è½®ï¼Œ{cloud_type}ç±»å‹ï¼Œæ·»åŠ {len(round_links)}ä¸ªé“¾æ¥")
                        links.extend(round_links)
        
        # å¦‚æœæ²¡æœ‰è½®æ¬¡æ’åˆ—çš„é“¾æ¥ï¼Œç›´æ¥è¿”å›æ‰€æœ‰æ”¶é›†åˆ°çš„é“¾æ¥
        if not links:
            logger.info(f"[PanSearch] æ²¡æœ‰è½®æ¬¡æ’åˆ—çš„é“¾æ¥ï¼Œç›´æ¥è¿”å›æ‰€æœ‰æ”¶é›†åˆ°çš„é“¾æ¥")
            for cloud_type in cloud_types:
                if cloud_type in all_links_by_type:
                    logger.info(f"[PanSearch] ç›´æ¥æ·»åŠ {cloud_type}ç±»å‹çš„{len(all_links_by_type[cloud_type])}ä¸ªé“¾æ¥")
                    links.extend(all_links_by_type[cloud_type][:max_links_per_type])
        
        logger.info(f"[PanSearch] æå–åˆ° {len(links)} ä¸ªé“¾æ¥")
        return links
    
    # å†…éƒ¨æ–¹æ³•ï¼šè½¬å­˜é“¾æ¥
    def _transfer_link(self, url: str, password: str = "") -> Optional[Dict]:
        try:
            api_url = f"{self.ziliao_api_url}{self.ziliao_api_path}"
            
            payload = {
                "url": url,
                "code": password,
                "expired_type": 1,
                "isType": 0
            }
            
            if self.ziliao_api_key:
                payload["api_key"] = self.ziliao_api_key
            
            headers = {
                "Content-Type": "application/x-www-form-urlencoded"
            }
            
            logger.info(f"[PanSearch] è½¬å­˜é“¾æ¥: {url[:50]}...")
            response = requests.post(
                api_url,
                data=payload,
                headers=headers,
                timeout=self.timeout
            )
            response.raise_for_status()
            
            result = response.json()
            
            if result.get("code") == 200 and result.get("data"):
                data = result.get("data", {})
                logger.info(f"[PanSearch] è½¬å­˜æˆåŠŸ")
                return data
            elif result.get("code") == 0 and result.get("data"):
                data = result.get("data", {})
                logger.info(f"[PanSearch] è½¬å­˜æˆåŠŸ")
                return data
            else:
                error_msg = result.get("message", result.get("error", "è½¬å­˜å¤±è´¥"))
                logger.error(f"[PanSearch] è½¬å­˜å¤±è´¥: {error_msg}")
                return None
                
        except requests.exceptions.RequestException as e:
            logger.error(f"[PanSearch] è½¬å­˜è¯·æ±‚å¼‚å¸¸: {str(e)}")
            return None
        except Exception as e:
            logger.error(f"[PanSearch] è½¬å­˜å¤„ç†å¼‚å¸¸: {str(e)}")
            return None
    
    # å†…éƒ¨æ–¹æ³•ï¼šæ ¼å¼åŒ–åˆ†é¡µç»“æœ
    def _format_results_page(self, results: List[Dict], page: int = 1) -> Tuple[str, int]:
        if not results:
            return "âŒ æ²¡æœ‰æ‰¾åˆ°ç»“æœ", 0
        
        total_pages = (len(results) + self.page_size - 1) // self.page_size
        
        if page < 1:
            page = 1
        if page > total_pages:
            page = total_pages
        
        start_idx = (page - 1) * self.page_size
        end_idx = start_idx + self.page_size
        page_results = results[start_idx:end_idx]
        
        output = f"ğŸ” æœç´¢ç»“æœï¼ˆå…± {len(results)} ä¸ªï¼Œç¬¬ {page}/{total_pages} é¡µï¼‰\n\n"
        
        for i, result in enumerate(page_results, start=start_idx + 1):
            cloud_type = result.get("type", "unknown")
            cloud_name = self.cloud_type_names.get(cloud_type, cloud_type)
            note = result.get("note", "æ— æ ‡é¢˜")
            
            output += f"ã€{i}ã€‘{note}\n"
            output += f"    ğŸ“¦ {cloud_name}\n"
            # æ·»åŠ åˆ†å‰²ç¬¦ï¼Œæœ€åä¸€ä¸ªç»“æœä¸æ·»åŠ 
            if i < end_idx and i < len(results):
                output += "" + "-" * 40 + "\n\n"
            else:
                output += "\n"
        
        if total_pages > 1:
            output += f"ğŸ’¡ è¾“å…¥ã€Œä¸‹ä¸€é¡µã€æˆ–ã€Œä¸Šä¸€é¡µã€ç¿»é¡µ\n"
            output += f"ğŸ’¡ è¾“å…¥ã€Œç¬¬Xä¸ªã€æˆ–ã€ŒXã€é€‰æ‹©èµ„æºï¼ˆå¦‚ï¼šç¬¬1ä¸ªã€1ï¼‰\n"
        
        return output, total_pages
    
    # å†…éƒ¨æ–¹æ³•ï¼šå¤„ç†æœç´¢
    def _handle_search(self, keyword: str, user_id: str, cloud_type: str = "all") -> str:
        self._cleanup_expired_sessions()
        
        try:
            # æœç´¢èµ„æº
            search_result = self._search_resources(keyword, cloud_type)
            logger.info(f"[PanSearch] _handle_search: æœç´¢ç»“æœ: {json.dumps(search_result)}")
            
            if not search_result:
                logger.info(f"[PanSearch] _handle_search: æœç´¢ç»“æœä¸ºç©º")
                return ">>>æŸ¥è¯¢å¤±è´¥<<<<\n--------------------\nå‰§åå®å°‘å†™ï¼Œä¸å¤šå†™ã€é”™å†™\nä¸è¦æ ‡ç‚¹ã€æ¼”å‘˜åã€ç¬¬å‡ å­£\nå¦‚å†æŸ¥è¯¢ä¸åˆ°@ç¾¤ä¸»å¸®ä½ æ‰¾"
            
            # è®¡ç®—å¯èƒ½çš„æ€»ç»“æœæ•°
            if isinstance(search_result, dict):
                # å°è¯•ä»ä¸åŒå­—æ®µè·å–æ€»ç»“æœæ•°
                total = search_result.get("total", 0)
                if total == 0:
                    # è®¡ç®—å®é™…å­˜åœ¨çš„é“¾æ¥æ•°
                    if "merged_by_type" in search_result:
                        total = sum(len(links) for links in search_result["merged_by_type"].values())
                    elif "links" in search_result:
                        total = len(search_result["links"])
            else:
                total = 0
            
            logger.info(f"[PanSearch] _handle_search: æ€»ç»“æœæ•°: {total}")
            
            if total == 0:
                return ">>>æŸ¥è¯¢å¤±è´¥<<<<\n--------------------\nå‰§åå®å°‘å†™ï¼Œä¸å¤šå†™ã€é”™å†™\nä¸è¦æ ‡ç‚¹ã€æ¼”å‘˜åã€ç¬¬å‡ å­£\nå¦‚å†æŸ¥è¯¢ä¸åˆ°@ç¾¤ä¸»å¸®ä½ æ‰¾"
            
            # æå–æ‰€æœ‰é“¾æ¥
            links = self._extract_all_links(search_result)
            logger.info(f"[PanSearch] _handle_search: æå–åˆ°çš„é“¾æ¥æ•°é‡: {len(links)}")
            if not links:
                return ">>>æŸ¥è¯¢å¤±è´¥<<<<\n--------------------\nå‰§åå®å°‘å†™ï¼Œä¸å¤šå†™ã€é”™å†™\nä¸è¦æ ‡ç‚¹ã€æ¼”å‘˜åã€ç¬¬å‡ å­£\nå¦‚å†æŸ¥è¯¢ä¸åˆ°@ç¾¤ä¸»å¸®ä½ æ‰¾"
            
            # ä¿å­˜åˆ°ä¼šè¯
            self.user_sessions[user_id] = {
                'keyword': keyword,
                'results': links,
                'timestamp': datetime.now(),
                'current_page': 1
            }
            
            # æ ¼å¼åŒ–ç¬¬ä¸€é¡µ
            output, total_pages = self._format_results_page(links, 1)
            return output
            
        except Exception as e:
            logger.error(f"æœç´¢å¤„ç†å¼‚å¸¸: {str(e)}")
            return f"âŒ æœç´¢å¤±è´¥: {str(e)}"
    
    # å†…éƒ¨æ–¹æ³•ï¼šå¤„ç†åˆ†é¡µå¯¼èˆª
    def _handle_page_navigation(self, direction: str, user_id: str) -> str:
        self._cleanup_expired_sessions()
        
        if user_id not in self.user_sessions:
            return "âŒ è¯·å…ˆæœç´¢èµ„æº"
        
        session = self.user_sessions[user_id]
        results = session['results']
        current_page = session.get('current_page', 1)
        total_pages = (len(results) + self.page_size - 1) // self.page_size
        
        if direction == "next":
            if current_page >= total_pages:
                return f"âŒ å·²ç»æ˜¯æœ€åä¸€é¡µäº†ï¼ˆå…± {total_pages} é¡µï¼‰"
            current_page += 1
        else:  # prev
            if current_page <= 1:
                return "âŒ å·²ç»æ˜¯ç¬¬ä¸€é¡µäº†"
            current_page -= 1
        
        session['current_page'] = current_page
        session['timestamp'] = datetime.now()
        
        output, _ = self._format_results_page(results, current_page)
        return output
    
    # å†…éƒ¨æ–¹æ³•ï¼šå¤„ç†é€‰æ‹©
    def _handle_select(self, selected_index: int, user_id: str) -> str:
        self._cleanup_expired_sessions()
        
        if user_id not in self.user_sessions:
            return "âŒ è¯·å…ˆæœç´¢èµ„æº"
        
        session = self.user_sessions[user_id]
        results = session['results']
        
        if selected_index < 1 or selected_index > len(results):
            return f"âŒ åºå·æ— æ•ˆï¼Œè¯·è¾“å…¥ 1-{len(results)} ä¹‹é—´çš„æ•°å­—"
        
        # è·å–é€‰ä¸­çš„èµ„æº
        selected_result = results[selected_index - 1]
        url = selected_result.get("url", "")
        password = selected_result.get("password", "")
        note = selected_result.get("note", "")
        cloud_type = selected_result.get("type", "")
        cloud_name = self.cloud_type_names.get(cloud_type, cloud_type)
        
        if not url:
            return "âŒ è¯¥èµ„æºé“¾æ¥æ— æ•ˆ"
        
        # æ‰§è¡Œè½¬å­˜
        output = f"â³ æ­£åœ¨è½¬å­˜ç¬¬ {selected_index} ä¸ªèµ„æº...\n"
        output += f"ğŸ“¦ ç±»å‹: {cloud_name}\n\n"
        
        transfer_result = self._transfer_link(url, password)
        
        if transfer_result:
            share_url = transfer_result.get("share_url", "")
            title = transfer_result.get("title", note)
            
            output = f"âœ… è½¬å­˜æˆåŠŸï¼\n\n"
            output += f"ğŸ“ æ ‡é¢˜: {title}\n"
            output += f"ğŸ”— é“¾æ¥: {share_url}\n"
            if password:
                output += f"ğŸ”‘ æå–ç : {password}\n"
            output += f"ğŸ“¦ ç½‘ç›˜: {cloud_name}\n"
            
            # æ›´æ–°ä¼šè¯æ—¶é—´æˆ³ï¼Œå»¶é•¿ä¼šè¯æœ‰æ•ˆæœŸ
            session['timestamp'] = datetime.now()
            
            return output
        else:
            error_message = "âŒ è½¬å­˜å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•\n\nâŒ è½¬å­˜å¤±è´¥ï¼Œè¯·æ›´æ¢é“¾æ¥"
            if self.group_owner_id:
                error_message += f"\n\n@{self.group_owner_id} ç¾¤ä¸»ï¼Œæœ‰äººè½¬å­˜å¤±è´¥äº†ï¼"
            return error_message
    
    # å†…éƒ¨æ–¹æ³•ï¼šå¤„ç†è½¬å­˜æŒ‡ä»¤
    def _handle_transfer(self, message_str: str, user_id: str) -> str:
        try:
            selected_index = int(message_str)
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = datetime.now()
            
            result = self._handle_select(selected_index, user_id)
            
            # è®¡ç®—è€—æ—¶
            end_time = datetime.now()
            elapsed_time = (end_time - start_time).total_seconds()
            
            # æ·»åŠ è€—æ—¶ä¿¡æ¯
            result += f"\nâ±ï¸  æœ¬æ¬¡æ“ä½œè€—æ—¶ï¼š{elapsed_time:.2f}ç§’"
            
            return result
        except ValueError:
            return "âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—åºå·"
